<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Web Scraping on Chris Albon</title>
    <link>https://chrisalbon.com/tags/web-scraping/</link>
    <description>Recent content in Web Scraping on Chris Albon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Dec 2017 11:53:49 -0700</lastBuildDate>
    
	<atom:link href="https://chrisalbon.com/tags/web-scraping/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Beautiful Soup Basic HTML Scraping</title>
      <link>https://chrisalbon.com/python/beautiful_soup_html_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/beautiful_soup_html_basics/</guid>
      <description>Import the modules # Import required modules import requests from bs4 import BeautifulSoup Scrap the html and turn into a beautiful soup object # Create a variable with the url url = &amp;#39;http://chrisralbon.com&amp;#39; # Use requests to get the contents r = requests.get(url) # Get the text of the contents html_content = r.text # Convert the html content into a beautiful soup object soup = BeautifulSoup(html_content, &amp;#39;lxml&amp;#39;) Select the website&amp;rsquo;s title # View the title tag of the soup object soup.</description>
    </item>
    
    <item>
      <title>Drilling Down With Beautiful Soup</title>
      <link>https://chrisalbon.com/python/beautiful_soup_drill_down/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/beautiful_soup_drill_down/</guid>
      <description>Preliminaries # Import required modules import requests from bs4 import BeautifulSoup import pandas as pd Download the HTML and create a Beautiful Soup object # Create a variable with the URL to this tutorial url = &amp;#39;http://en.wikipedia.org/wiki/List_of_A_Song_of_Ice_and_Fire_characters&amp;#39; # Scrape the HTML at the url r = requests.get(url) # Turn the HTML into a Beautiful Soup object soup = BeautifulSoup(r.text, &amp;#34;lxml&amp;#34;) If we looked at the soup object, we&amp;rsquo;d see that the names we want are in a heirarchical list.</description>
    </item>
    
  </channel>
</rss>