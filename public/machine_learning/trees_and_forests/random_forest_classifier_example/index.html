<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Random Forest Classifier Example" />
<meta property="og:description" content="random_forest_classifier_example using Scikit." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/" />



<meta property="article:published_time" content="2017-12-20T11:53:49-07:00"/>

<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00"/>











<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Random Forest Classifier Example"/>
<meta name="twitter:description" content="random_forest_classifier_example using Scikit."/>
<meta name="generator" content="Hugo 0.31.1" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Random Forest Classifier Example",
  "url": "https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/",
  "wordCount": "1610",
  "datePublished": "2017-12-20T11:53:49-07:00",
  "dateModified": "2017-12-20T11:53:49-07:00",
  "author": {
    "@type": "Person",
    "name": "Chris Albon"
  },
  "description": "random_forest_classifier_example using Scikit."
}
</script>



    <link rel="canonical" href="https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/">

    <title>Random Forest Classifier Example | Chris Albon</title>

    <!-- combined, minified CSS -->
    <link href="https://chrisalbon.com/css/style.css" rel="stylesheet" integrity="" crossorigin="anonymous">
    <link href="https://chrisalbon.com/css/main.css" rel="stylesheet" integrity="" crossorigin="anonymous">

    

    

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

  </head>

  <body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="nav blog-nav">
          <a class="nav-link" href="https://chrisalbon.com/">Home</a></nav>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-sm-12 blog-main">

          


<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/">Random Forest Classifier Example</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-20T11:53:49-07:00">Wed Dec 20, 2017</time></p>
  </header>
  

<p>This tutorial is based on Yhat&rsquo;s 2013 tutorial on <a href="http://blog.yhat.com/posts/random-forests-in-python.html">Random Forests in Python</a>. If you want a good summary of the theory and uses of random forests, I suggest you check out their guide. In the tutorial below, I annotate, correct, and expand on a short code example of random forests they present at the end of the article. Specifically, I 1) update the code so it runs in the latest version of pandas and Python, 2) write detailed comments explaining what is happening in each step, and 3) expand the code in a number of ways.</p>

<p>Let&rsquo;s get started!</p>

<h3 id="a-note-about-the-data">A Note About The Data</h3>

<p>The data for this tutorial is famous. Called, <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">the iris dataset</a>, it contains four variables measuring various parts of iris flowers of three related species, and then a fourth variable with the species name. The reason it is so famous in machine learning and statistics communities is because the data requires very little preprocessing (i.e. no missing values, all features are floating numbers, etc.).</p>

<h2 id="preliminaries">Preliminaries</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Load the library with the iris dataset</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.datasets</span> <span style="color:#080;font-weight:bold">import</span> load_iris

<span style="color:#888"># Load scikit&#39;s random forest classifier library</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.ensemble</span> <span style="color:#080;font-weight:bold">import</span> RandomForestClassifier

<span style="color:#888"># Load pandas</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">pandas</span> <span style="color:#080;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">pd</span>

<span style="color:#888"># Load numpy</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#080;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>

<span style="color:#888"># Set random seed</span>
np<span style="color:#333">.</span>random<span style="color:#333">.</span>seed(<span style="color:#00d;font-weight:bold">0</span>)</code></pre></div>
<h2 id="load-data">Load Data</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create an object called iris with the iris data</span>
iris <span style="color:#333">=</span> load_iris()

<span style="color:#888"># Create a dataframe with the four feature variables</span>
df <span style="color:#333">=</span> pd<span style="color:#333">.</span>DataFrame(iris<span style="color:#333">.</span>data, columns<span style="color:#333">=</span>iris<span style="color:#333">.</span>feature_names)

<span style="color:#888"># View the top 5 rows</span>
df<span style="color:#333">.</span>head()</code></pre></div>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Add a new column with the species names, this is what we are going to try to predict</span>
df[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;species&#39;</span>] <span style="color:#333">=</span> pd<span style="color:#333">.</span>Categorical<span style="color:#333">.</span>from_codes(iris<span style="color:#333">.</span>target, iris<span style="color:#333">.</span>target_names)

<span style="color:#888"># View the top 5 rows</span>
df<span style="color:#333">.</span>head()</code></pre></div>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="create-training-and-test-data">Create Training And Test Data</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create a new column that for each row, generates a random number between 0 and 1, and</span>
<span style="color:#888"># if that value is less than or equal to .75, then sets the value of that cell as True</span>
<span style="color:#888"># and false otherwise. This is a quick and dirty way of randomly assigning some rows to</span>
<span style="color:#888"># be used as the training data and some as the test data.</span>
df[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;is_train&#39;</span>] <span style="color:#333">=</span> np<span style="color:#333">.</span>random<span style="color:#333">.</span>uniform(<span style="color:#00d;font-weight:bold">0</span>, <span style="color:#00d;font-weight:bold">1</span>, <span style="color:#007020">len</span>(df)) <span style="color:#333">&lt;=</span> <span style="color:#333">.</span><span style="color:#00d;font-weight:bold">75</span>

<span style="color:#888"># View the top 5 rows</span>
df<span style="color:#333">.</span>head()</code></pre></div>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>species</th>
      <th>is_train</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create two new dataframes, one with the training rows, one with the test rows</span>
train, test <span style="color:#333">=</span> df[df[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;is_train&#39;</span>]<span style="color:#333">==</span>True], df[df[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;is_train&#39;</span>]<span style="color:#333">==</span>False]</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Show the number of observations for the test and training dataframes</span>
<span style="color:#080;font-weight:bold">print</span>(<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;Number of observations in the training data:&#39;</span>, <span style="color:#007020">len</span>(train))
<span style="color:#080;font-weight:bold">print</span>(<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;Number of observations in the test data:&#39;</span>,<span style="color:#007020">len</span>(test))</code></pre></div>
<pre><code>Number of observations in the training data: 118
Number of observations in the test data: 32
</code></pre>

<h2 id="preprocess-data">Preprocess Data</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create a list of the feature column&#39;s names</span>
features <span style="color:#333">=</span> df<span style="color:#333">.</span>columns[:<span style="color:#00d;font-weight:bold">4</span>]

<span style="color:#888"># View features</span>
features</code></pre></div>
<pre><code>Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',
       'petal width (cm)'],
      dtype='object')
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># train[&#39;species&#39;] contains the actual species names. Before we can use it,</span>
<span style="color:#888"># we need to convert each species name into a digit. So, in this case there</span>
<span style="color:#888"># are three species, which have been coded as 0, 1, or 2.</span>
y <span style="color:#333">=</span> pd<span style="color:#333">.</span>factorize(train[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;species&#39;</span>])[<span style="color:#00d;font-weight:bold">0</span>]

<span style="color:#888"># View target</span>
y</code></pre></div>
<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2])
</code></pre>

<h2 id="train-the-random-forest-classifier">Train The Random Forest Classifier</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create a random forest Classifier. By convention, clf means &#39;Classifier&#39;</span>
clf <span style="color:#333">=</span> RandomForestClassifier(n_jobs<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">2</span>, random_state<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">0</span>)

<span style="color:#888"># Train the Classifier to take the training features and learn how they relate</span>
<span style="color:#888"># to the training y (the species)</span>
clf<span style="color:#333">.</span>fit(train[features], y)</code></pre></div>
<pre><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=10, n_jobs=2, oob_score=False, random_state=0,
            verbose=0, warm_start=False)
</code></pre>

<p>Huzzah! We have done it! We have officially trained our random forest Classifier! Now let&rsquo;s play with it. The Classifier model itself is stored in the <code>clf</code> variable.</p>

<h2 id="apply-classifier-to-test-data">Apply Classifier To Test Data</h2>

<p>If you have been following along, you will know we only trained our classifier on part of the data, leaving the rest out. This is, in my humble opinion, the most important part of machine learning. Why? Because by leaving out a portion of the data, we have a set of data to test the accuracy of our model!</p>

<p>Let&rsquo;s do that now.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Apply the Classifier we trained to the test data (which, remember, it has never seen before)</span>
clf<span style="color:#333">.</span>predict(test[features])</code></pre></div>
<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2])
</code></pre>

<p>What are you looking at above? Remember that we coded each of the three species of plant as 0, 1, or 2. What the list of numbers above is showing you is what species our model predicts each plant is based on the the sepal length, sepal width, petal length, and petal width. How confident is the classifier about each plant? We can see that too.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View the predicted probabilities of the first 10 observations</span>
clf<span style="color:#333">.</span>predict_proba(test[features])[<span style="color:#00d;font-weight:bold">0</span>:<span style="color:#00d;font-weight:bold">10</span>]</code></pre></div>
<pre><code>array([[ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 0.9,  0.1,  0. ],
       [ 1. ,  0. ,  0. ],
       [ 1. ,  0. ,  0. ]])
</code></pre>

<p>There are three species of plant, thus <code>[ 1. ,  0. ,  0. ]</code> tells us that the classifier is certain that the plant is the first class. Taking another example, <code>[ 0.9,  0.1,  0. ]</code> tells us that the classifier gives a 90% probability the plant belongs to the first class and a 10% probability the plant belongs to the second class. Because 90 is greater than 10, the classifier predicts the plant is the first class.</p>

<h2 id="evaluate-classifier">Evaluate Classifier</h2>

<p>Now that we have predicted the species of all plants in the test data, we can compare our predicted species with the that plant&rsquo;s actual species.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create actual english names for the plants for each predicted plant class</span>
preds <span style="color:#333">=</span> iris<span style="color:#333">.</span>target_names[clf<span style="color:#333">.</span>predict(test[features])]</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View the PREDICTED species for the first five observations</span>
preds[<span style="color:#00d;font-weight:bold">0</span>:<span style="color:#00d;font-weight:bold">5</span>]</code></pre></div>
<pre><code>array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa'],
      dtype='&lt;U10')
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View the ACTUAL species for the first five observations</span>
test[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;species&#39;</span>]<span style="color:#333">.</span>head()</code></pre></div>
<pre><code>7     setosa
8     setosa
10    setosa
13    setosa
17    setosa
Name: species, dtype: category
Categories (3, object): [setosa, versicolor, virginica]
</code></pre>

<p>That looks pretty good! At least for the first five observations. Now let&rsquo;s use look at all the data.</p>

<h3 id="create-a-confusion-matrix">Create a confusion matrix</h3>

<p>A <a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a> can be, no pun intended, a little confusing to interpret at first, but it is actually very straightforward. The columns are the species we predicted for the test data and the rows are the actual species for the test data. So, if we take the top row, we can wee that we predicted all 13 setosa plants in the test data perfectly. However, in the next row, we predicted 5 of the versicolor plants correctly, but mis-predicted two of the versicolor plants as virginica.</p>

<p>The short explanation of how to interpret a confusion matrix is: anything on the diagonal was classified correctly and anything off the diagonal was classified incorrectly.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create confusion matrix</span>
pd<span style="color:#333">.</span>crosstab(test[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;species&#39;</span>], preds, rownames<span style="color:#333">=</span>[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;Actual Species&#39;</span>], colnames<span style="color:#333">=</span>[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;Predicted Species&#39;</span>])</code></pre></div>
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Predicted Species</th>
      <th>setosa</th>
      <th>versicolor</th>
      <th>virginica</th>
    </tr>
    <tr>
      <th>Actual Species</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>setosa</th>
      <td>13</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>versicolor</th>
      <td>0</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>virginica</th>
      <td>0</td>
      <td>0</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="view-feature-importance">View Feature Importance</h2>

<p>While we don&rsquo;t get regression coefficients like with OLS, we do get a score telling us how important each feature was in classifying. This is one of the most powerful parts of random forests, because we can clearly see that petal width was more important in classification than sepal width.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View a list of the features and their importance scores</span>
<span style="color:#007020">list</span>(<span style="color:#007020">zip</span>(train[features], clf<span style="color:#333">.</span>feature_importances_))</code></pre></div>
<pre><code>[('sepal length (cm)', 0.11185992930506346),
 ('sepal width (cm)', 0.016341813006098178),
 ('petal length (cm)', 0.36439533040889194),
 ('petal width (cm)', 0.5074029272799464)]
</code></pre>


</article> 



        </div> <!-- /.blog-main -->

      </div> <!-- /.row -->
    </div> <!-- /.container -->

    <footer class="blog-footer">
      <p>
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
    </footer>

  </body>

</html>
