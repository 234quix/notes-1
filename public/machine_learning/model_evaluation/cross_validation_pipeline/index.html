<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Cross Validation Pipeline" />
<meta property="og:description" content="Cross validaton pipeline with scikit." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/" />



<meta property="article:published_time" content="2017-12-20T11:53:49-07:00"/>

<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00"/>











<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Cross Validation Pipeline"/>
<meta name="twitter:description" content="Cross validaton pipeline with scikit."/>
<meta name="generator" content="Hugo 0.31.1" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Cross Validation Pipeline",
  "url": "https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/",
  "wordCount": "461",
  "datePublished": "2017-12-20T11:53:49-07:00",
  "dateModified": "2017-12-20T11:53:49-07:00",
  "author": {
    "@type": "Person",
    "name": "Chris Albon"
  },
  "description": "Cross validaton pipeline with scikit."
}
</script>



    <link rel="canonical" href="https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/">

    <title>Cross Validation Pipeline | Chris Albon</title>

    <!-- combined, minified CSS -->
    <link href="https://chrisalbon.com/css/style.css" rel="stylesheet" integrity="" crossorigin="anonymous">
    <link href="https://chrisalbon.com/css/main.css" rel="stylesheet" integrity="" crossorigin="anonymous">

    

    

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

  </head>

  <body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="nav blog-nav">
          <a class="nav-link" href="https://chrisalbon.com/">Home</a></nav>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-sm-12 blog-main">

          


<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/">Cross Validation Pipeline</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-20T11:53:49-07:00">Wed Dec 20, 2017</time></p>
  </header>
  

<p>The code below does a lot in only a few lines. To help explain things, here are the steps that code is doing:</p>

<ol>
<li>Split the raw data into three folds. Select one for testing and two for training.</li>
<li>Preprocess the data by scaling the training features.</li>
<li>Train a support vector classifier on the training data.</li>
<li>Apply the classifier to the test data.</li>
<li>Record the accuracy score.</li>
<li>Repeat steps 1-5 two more times, once for each fold.</li>
<li>Calculate the mean score for all the folds.</li>
</ol>

<h2 id="preliminaries">Preliminaries</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.datasets</span> <span style="color:#080;font-weight:bold">import</span> load_iris
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.pipeline</span> <span style="color:#080;font-weight:bold">import</span> make_pipeline
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn</span> <span style="color:#080;font-weight:bold">import</span> preprocessing
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn</span> <span style="color:#080;font-weight:bold">import</span> cross_validation
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn</span> <span style="color:#080;font-weight:bold">import</span> svm</code></pre></div>
<h2 id="load-data">Load Data</h2>

<p>For this tutorial we will use the famous <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">iris dataset</a>. The iris data contains four measurements of 150 iris flowers and their species. We will use a support vector classifier to predict the species of the iris flowers.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Load the iris test data</span>
iris <span style="color:#333">=</span> load_iris()</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View the iris data features for the first three rows</span>
iris<span style="color:#333">.</span>data[<span style="color:#00d;font-weight:bold">0</span>:<span style="color:#00d;font-weight:bold">3</span>]</code></pre></div>
<pre><code>array([[ 5.1,  3.5,  1.4,  0.2],
       [ 4.9,  3. ,  1.4,  0.2],
       [ 4.7,  3.2,  1.3,  0.2]])
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># View the iris data target for first three rows. &#39;0&#39; means it flower is of the setosa species.</span>
iris<span style="color:#333">.</span>target[<span style="color:#00d;font-weight:bold">0</span>:<span style="color:#00d;font-weight:bold">3</span>]</code></pre></div>
<pre><code>array([0, 0, 0])
</code></pre>

<h2 id="create-classifier-pipeline">Create Classifier Pipeline</h2>

<p>Now we create a pipeline for the data. First, the pipeline preprocesses the data by scaling the feature variable&rsquo;s values to mean zero and unit variance. Second, the pipeline trains a support classifier on the data with <code>C=1</code>. <code>C</code> is the cost function for the margins. The higher the C, the less tolerant the model is for observations being on the wrong side of the hyperplane.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create a pipeline that scales the data then trains a support vector classifier</span>
classifier_pipeline <span style="color:#333">=</span> make_pipeline(preprocessing<span style="color:#333">.</span>StandardScaler(), svm<span style="color:#333">.</span>SVC(C<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">1</span>))</code></pre></div>
<h2 id="cross-validation">Cross Validation</h2>

<p>Scikit provides a great helper function to make it easy to do cross validation. Specifically, the code below splits the data into three folds, then executes the classifier pipeline on the iris data.</p>

<p>Important note from the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score">scikit docs</a>: <em>For integer/None inputs, if y is binary or multiclass, StratifiedKFold used. If the estimator is a classifier or if y is neither binary nor multiclass, KFold is used.</em></p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># KFold/StratifiedKFold cross validation with 3 folds (the default)</span>
<span style="color:#888"># applying the classifier pipeline to the feature and target data</span>
scores <span style="color:#333">=</span> cross_validation<span style="color:#333">.</span>cross_val_score(classifier_pipeline, iris<span style="color:#333">.</span>data, iris<span style="color:#333">.</span>target, cv<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">3</span>)</code></pre></div>
<h2 id="evaluate-model">Evaluate Model</h2>

<p>Here is the output of our 3 KFold cross validation. Each value is the accuracy score of the support vector classifier when leaving out a different fold. There are three values because there are three folds. A higher accuracy score, the better.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">scores</code></pre></div>
<pre><code>array([ 0.98039216,  0.90196078,  0.97916667])
</code></pre>

<p>To get an good measure of the model&rsquo;s accuracy, we calculate the mean of the three scores. This is our measure of model accuracy.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">scores<span style="color:#333">.</span>mean()</code></pre></div>
<pre><code>0.95383986928104569
</code></pre>


</article> 



        </div> <!-- /.blog-main -->

      </div> <!-- /.row -->
    </div> <!-- /.container -->

    <footer class="blog-footer">
      <p>
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
    </footer>

  </body>

</html>
