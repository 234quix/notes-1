<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="k-Fold Cross-Validating Neural Networks" />
<meta property="og:description" content="How to k-fold cross-validate neural networks for deep learning in Python." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/" />



<meta property="article:published_time" content="2017-12-20T11:53:49-07:00"/>

<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00"/>











<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="k-Fold Cross-Validating Neural Networks"/>
<meta name="twitter:description" content="How to k-fold cross-validate neural networks for deep learning in Python."/>
<meta name="generator" content="Hugo 0.31.1" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "k-Fold Cross-Validating Neural Networks",
  "url": "https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/",
  "wordCount": "333",
  "datePublished": "2017-12-20T11:53:49-07:00",
  "dateModified": "2017-12-20T11:53:49-07:00",
  "author": {
    "@type": "Person",
    "name": "Chris Albon"
  },
  "description": "How to k-fold cross-validate neural networks for deep learning in Python."
}
</script>



    <link rel="canonical" href="https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/">

    <title>k-Fold Cross-Validating Neural Networks | Chris Albon</title>

    <!-- combined, minified CSS -->
    <link href="https://chrisalbon.com/css/style.css" rel="stylesheet" integrity="" crossorigin="anonymous">
    <link href="https://chrisalbon.com/css/main.css" rel="stylesheet" integrity="" crossorigin="anonymous">

    

    

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

  </head>

  <body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="nav blog-nav">
          <a class="nav-link" href="https://chrisalbon.com/">Home</a></nav>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-sm-12 blog-main">

          


<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/">k-Fold Cross-Validating Neural Networks</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-20T11:53:49-07:00">Wed Dec 20, 2017</time></p>
  </header>
  

<p>If we have smaller data it can be useful to benefit from k-fold cross-validation to maximize our ability to evaluate the neural network&rsquo;s performance. This is possible in Keras because we can &ldquo;wrap&rdquo; any neural network such that it can use the evaluation features available in scikit-learn, including k-fold cross-validation. To accomplish this, we first have to create a function that returns a compiled neural network. Next we use <code>KerasClassifier</code> (if we have a classifier, if we have a regressor we can use <code>KerasRegressor</code>) to wrap the model so it can be used by scikit-learn. After this, we can use our neural network like any other scikit-learn learning algorithm (e.g. random forests, logistic regression). In our solution, we used <code>cross_val_score</code> to run a 3-fold cross-validation on our neural network.</p>

<h2 id="preliminaries">Preliminaries</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Load libraries</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#080;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras</span> <span style="color:#080;font-weight:bold">import</span> models
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras</span> <span style="color:#080;font-weight:bold">import</span> layers
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras.wrappers.scikit_learn</span> <span style="color:#080;font-weight:bold">import</span> KerasClassifier
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.model_selection</span> <span style="color:#080;font-weight:bold">import</span> cross_val_score
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">sklearn.datasets</span> <span style="color:#080;font-weight:bold">import</span> make_classification

<span style="color:#888"># Set random seed</span>
np<span style="color:#333">.</span>random<span style="color:#333">.</span>seed(<span style="color:#00d;font-weight:bold">0</span>)</code></pre></div>
<pre><code>Using TensorFlow backend.
</code></pre>

<h2 id="create-feature-and-target-data">Create Feature And Target Data</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Number of features</span>
number_of_features <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">100</span>

<span style="color:#888"># Generate features matrix and target vector</span>
features, target <span style="color:#333">=</span> make_classification(n_samples <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">10000</span>,
                                       n_features <span style="color:#333">=</span> number_of_features,
                                       n_informative <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">3</span>,
                                       n_redundant <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">0</span>,
                                       n_classes <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">2</span>,
                                       weights <span style="color:#333">=</span> [<span style="color:#333">.</span><span style="color:#00d;font-weight:bold">5</span>, <span style="color:#333">.</span><span style="color:#00d;font-weight:bold">5</span>],
                                       random_state <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">0</span>)</code></pre></div>
<h2 id="create-function-that-constructs-neural-network">Create Function That Constructs Neural Network</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Create function returning a compiled network</span>
<span style="color:#080;font-weight:bold">def</span> <span style="color:#06b;font-weight:bold">create_network</span>():
    
    <span style="color:#888"># Start neural network</span>
    network <span style="color:#333">=</span> models<span style="color:#333">.</span>Sequential()

    <span style="color:#888"># Add fully connected layer with a ReLU activation function</span>
    network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">16</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;relu&#39;</span>, input_shape<span style="color:#333">=</span>(number_of_features,)))

    <span style="color:#888"># Add fully connected layer with a ReLU activation function</span>
    network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">16</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;relu&#39;</span>))

    <span style="color:#888"># Add fully connected layer with a sigmoid activation function</span>
    network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">1</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;sigmoid&#39;</span>))

    <span style="color:#888"># Compile neural network</span>
    network<span style="color:#333">.</span><span style="color:#007020">compile</span>(loss<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;binary_crossentropy&#39;</span>, <span style="color:#888"># Cross-entropy</span>
                    optimizer<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;rmsprop&#39;</span>, <span style="color:#888"># Root Mean Square Propagation</span>
                    metrics<span style="color:#333">=</span>[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;accuracy&#39;</span>]) <span style="color:#888"># Accuracy performance metric</span>
    
    <span style="color:#888"># Return compiled network</span>
    <span style="color:#080;font-weight:bold">return</span> network</code></pre></div>
<h2 id="wrap-function-in-kerasclassifier">Wrap Function In KerasClassifier</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Wrap Keras model so it can be used by scikit-learn</span>
neural_network <span style="color:#333">=</span> KerasClassifier(build_fn<span style="color:#333">=</span>create_network, 
                                 epochs<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">10</span>, 
                                 batch_size<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">100</span>, 
                                 verbose<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">0</span>)</code></pre></div>
<h2 id="conduct-k-fold-cross-validation-using-scikit-learn">Conduct k-Fold Cross-Validation Using scikit-learn</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Evaluate neural network using three-fold cross-validation</span>
cross_val_score(neural_network, features, target, cv<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">3</span>)</code></pre></div>
<pre><code>array([ 0.90491901,  0.77827782,  0.87038704])
</code></pre>


</article> 



        </div> <!-- /.blog-main -->

      </div> <!-- /.row -->
    </div> <!-- /.container -->

    <footer class="blog-footer">
      <p>
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
    </footer>

  </body>

</html>
