<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Save Model Training Progress" />
<meta property="og:description" content="How to save neural networking model training progress for deep learning in Python." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chrisalbon.com/deep_learning/keras/save_model_training_progress/" />



<meta property="article:published_time" content="2017-12-20T11:53:49-07:00"/>

<meta property="article:modified_time" content="2017-12-20T11:53:49-07:00"/>











<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Save Model Training Progress"/>
<meta name="twitter:description" content="How to save neural networking model training progress for deep learning in Python."/>
<meta name="generator" content="Hugo 0.31.1" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Save Model Training Progress",
  "url": "https://chrisalbon.com/deep_learning/keras/save_model_training_progress/",
  "wordCount": "357",
  "datePublished": "2017-12-20T11:53:49-07:00",
  "dateModified": "2017-12-20T11:53:49-07:00",
  "author": {
    "@type": "Person",
    "name": "Chris Albon"
  },
  "description": "How to save neural networking model training progress for deep learning in Python."
}
</script>



    <link rel="canonical" href="https://chrisalbon.com/deep_learning/keras/save_model_training_progress/">

    <title>Save Model Training Progress | Chris Albon</title>

    <!-- combined, minified CSS -->
    <link href="https://chrisalbon.com/css/style.css" rel="stylesheet" integrity="" crossorigin="anonymous">
    <link href="https://chrisalbon.com/css/main.css" rel="stylesheet" integrity="" crossorigin="anonymous">

    

    

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

  </head>

  <body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="nav blog-nav">
          <a class="nav-link" href="https://chrisalbon.com/">Home</a></nav>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-sm-12 blog-main">

          


<article class="blog-post">
  <header>
    <h2 class="blog-post-title"><a href="https://chrisalbon.com/deep_learning/keras/save_model_training_progress/">Save Model Training Progress</a></h2>
    <p class="blog-post-meta"><time datetime="2017-12-20T11:53:49-07:00">Wed Dec 20, 2017</time></p>
  </header>
  

<h2 id="preliminaries">Preliminaries</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Load libraries</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#080;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras.datasets</span> <span style="color:#080;font-weight:bold">import</span> imdb
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras.preprocessing.text</span> <span style="color:#080;font-weight:bold">import</span> Tokenizer
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras</span> <span style="color:#080;font-weight:bold">import</span> models
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras</span> <span style="color:#080;font-weight:bold">import</span> layers
<span style="color:#080;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">keras.callbacks</span> <span style="color:#080;font-weight:bold">import</span> ModelCheckpoint

<span style="color:#888"># Set random seed</span>
np<span style="color:#333">.</span>random<span style="color:#333">.</span>seed(<span style="color:#00d;font-weight:bold">0</span>)</code></pre></div>
<h2 id="load-imdb-movie-review-data">Load IMDB Movie Review Data</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Set the number of features we want</span>
number_of_features <span style="color:#333">=</span> <span style="color:#00d;font-weight:bold">1000</span>

<span style="color:#888"># Load data and target vector from movie review data</span>
(train_data, train_target), (test_data, test_target) <span style="color:#333">=</span> imdb<span style="color:#333">.</span>load_data(num_words<span style="color:#333">=</span>number_of_features)

<span style="color:#888"># Convert movie review data to a one-hot encoded feature matrix</span>
tokenizer <span style="color:#333">=</span> Tokenizer(num_words<span style="color:#333">=</span>number_of_features)
train_features <span style="color:#333">=</span> tokenizer<span style="color:#333">.</span>sequences_to_matrix(train_data, mode<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;binary&#39;</span>)
test_features <span style="color:#333">=</span> tokenizer<span style="color:#333">.</span>sequences_to_matrix(test_data, mode<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;binary&#39;</span>)</code></pre></div>
<h2 id="create-neural-network-architecture">Create Neural Network Architecture</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Start neural network</span>
network <span style="color:#333">=</span> models<span style="color:#333">.</span>Sequential()

<span style="color:#888"># Add fully connected layer with a ReLU activation function</span>
network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">16</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;relu&#39;</span>, input_shape<span style="color:#333">=</span>(number_of_features,)))

<span style="color:#888"># Add fully connected layer with a ReLU activation function</span>
network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">16</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;relu&#39;</span>))

<span style="color:#888"># Add fully connected layer with a sigmoid activation function</span>
network<span style="color:#333">.</span>add(layers<span style="color:#333">.</span>Dense(units<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">1</span>, activation<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;sigmoid&#39;</span>))</code></pre></div>
<h2 id="compile-neural-network">Compile Neural Network</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Compile neural network</span>
network<span style="color:#333">.</span><span style="color:#007020">compile</span>(loss<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;binary_crossentropy&#39;</span>, <span style="color:#888"># Cross-entropy</span>
                optimizer<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;rmsprop&#39;</span>, <span style="color:#888"># Root Mean Square Propagation</span>
                metrics<span style="color:#333">=</span>[<span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;accuracy&#39;</span>]) <span style="color:#888"># Accuracy performance metric</span></code></pre></div>
<h2 id="save-training-progress-after-each-epoch">Save Training Progress After Each Epoch</h2>

<p>After every epoch <code>ModelCheckpoint</code> saves a model to the location specified by the <code>filepath</code> parameter. If we include only a filename (e.g. <code>models.hdf5</code>) that file will be overridden with the latest model every epoch. If we only wanted to save the best model according to the performance of some loss function, we can set <code>save_best_only=True</code> and <code>monitor='val_loss'</code> to not override a file if the model has a worse test loss than the previous model. Alternatively, we can save every epoch&rsquo;s model as its own file by including the epoch number and test loss score into the filename itself. For example if we set <code>filepath</code> to <code>model_{epoch:02d}_{val_loss:.2f}.hdf5</code>, the name of the file containing the model saved after the 11th epoch with a test loss value of 0.33 would be <code>model_10_0.35.hdf5</code> (notice that the epoch number if 0-indexed).</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Set callback functions to early stop training and save the best model so far</span>
checkpoint <span style="color:#333">=</span> [ModelCheckpoint(filepath<span style="color:#333">=</span><span style="background-color:#fff0f0"></span><span style="background-color:#fff0f0">&#39;models.hdf5&#39;</span>)]</code></pre></div>
<h2 id="train-neural-network">Train Neural Network</h2>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#888"># Train neural network</span>
history <span style="color:#333">=</span> network<span style="color:#333">.</span>fit(train_features, <span style="color:#888"># Features</span>
                      train_target, <span style="color:#888"># Target vector</span>
                      epochs<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">3</span>, <span style="color:#888"># Number of epochs</span>
                      callbacks<span style="color:#333">=</span>checkpoint, <span style="color:#888"># Checkpoint</span>
                      verbose<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">0</span>, <span style="color:#888"># No output</span>
                      batch_size<span style="color:#333">=</span><span style="color:#00d;font-weight:bold">100</span>, <span style="color:#888"># Number of observations per batch</span>
                      validation_data<span style="color:#333">=</span>(test_features, test_target)) <span style="color:#888"># Data for evaluation</span></code></pre></div>

</article> 



        </div> <!-- /.blog-main -->

      </div> <!-- /.row -->
    </div> <!-- /.container -->

    <footer class="blog-footer">
      <p>
      
      Blog template created by <a href="https://twitter.com/mdo">@mdo</a>, ported to Hugo by <a href='https://twitter.com/mralanorth'>@mralanorth</a>.
      
      </p>
    </footer>

  </body>

</html>
